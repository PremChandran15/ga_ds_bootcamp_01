{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for class Imbalances and store some data away for test purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection and Feature Importance\n",
    "Perform Feature Selection and Importance\n",
    "\n",
    "#### Perform Encoding and Standard Scaler\n",
    "Since the data has many categorical variables, it is best to first perform ordinal encoding and standard scaling first as most ML algorithms work best with scaled datasets.\n",
    "\n",
    "***Note on Encoding***: The encoding type chosen for this exercise is Ordinal Encoder, which is not as robust as OneHotEncoder due to the order can be misinterpretaed by the ML algorithm at times. But OneHotEncoder can pose another challenge which is data cardinality and huge matrix which will then need to be cleaned with PCA etc. So for that reason and in interest of time, Ordinal Encoder will be used. More information can be retrieved from this [sklearn site](https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "The dataset will be trained using classification algorithms, namely Logistic Regression, Random Forest, and ANN but first a metric will be set to compare with later\n",
    "\n",
    "### Evaluation Metrics - Naive Predictor (Benchmark model)\n",
    "\n",
    "In this section, we will attempt to create a Benchmark model which is a Naive Predictor. The assumption is to naively say that all bookings will not be cancelled. So, that will be my attempt here to set all target labels to zero, and then predict the ROC_AUC score on the Naive Predictor. It should give around 50% ROC score as it is sort of a random predictor.\n",
    "\n",
    "Hotel booking cancellation is a solution for the Hotel Owner (Objective to predict cancellation). Hence it will be a bigger loss if there is a wrong prediction on saying that the booking will not be cancelled, but ended up cancelling it (False Negative - Type 2 Error) as there will be revenue loss rather than wrongly prediction cancellations (False Positive - Type 1 Error). Hence Type 2 error need to be avoided, which means recall score needs to be optimized. Since ROC-AUC will look to optimize both TPR and 1-TNR, this will be the main metric used. However, to optimize the grid-search algorithm below, F-Beta score with a Beta value of 2 is also used to optimize recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an array of zeros for the length of training set\n",
    "\n",
    "    \n",
    "#Check the roc score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Best Sklearn Model Using GridSearchCV\n",
    "\n",
    "### ExtraTreesClassifier and Logistic Regression Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving best models\n",
    "\n",
    "### Running predictions to validate\n",
    "Randomly run predictions to validate from the True Negatives set earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
